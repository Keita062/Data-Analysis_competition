{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4830e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import MeCab\n",
    "import ipadic\n",
    "import re\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fcaebc",
   "metadata": {},
   "source": [
    "### 前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f509b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MeCabの初期化\n",
    "tagger = MeCab.Tagger(ipadic.MECAB_ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e08de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns(text):\n",
    "    \"\"\"文章から分析に適した名詞を抽出する\"\"\"\n",
    "    if pd.isna(text): return []\n",
    "    node = tagger.parseToNode(text)\n",
    "    nouns = []\n",
    "    while node:\n",
    "        features = node.feature.split(',')\n",
    "        # 一般名詞、固有名詞、サ変接続を対象\n",
    "        if features[0] == '名詞' and features[1] in ['一般', '固有名詞', 'サ変接続']:\n",
    "            if len(node.surface) > 1:\n",
    "                nouns.append(node.surface)\n",
    "        node = node.next\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6090d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv(r'C:\\Users\\管理\\Documents\\GitHub\\Data-Analysis_competition\\Analysis\\sigante_anime\\Data\\base_stories.tsv', sep='\\t')\n",
    "practice_df = pd.read_csv(r'C:\\Users\\管理\\Documents\\GitHub\\Data-Analysis_competition\\Analysis\\sigante_anime\\Data\\fiction_stories_practice.tsv', sep='\\t')\n",
    "test_df = pd.read_csv(r'C:\\Users\\管理\\Documents\\GitHub\\Data-Analysis_competition\\Analysis\\sigante_anime\\Data\\fiction_stories_test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a6ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_base = [extract_nouns(s) for s in base_df['story']]\n",
    "bm25 = BM25Okapi(tokenized_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f77b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4b40ac0c4f423c9a6f034e6ebf6805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: intfloat/multilingual-e5-small\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('intfloat/multilingual-e5-small')\n",
    "base_embeddings = model.encode([\"passage: \" + s for s in base_df['story']], normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab18a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_window_search(query_story, k=60):\n",
    "    \"\"\"スライディングウィンドウ + RRFによるハイブリッド検索\"\"\"\n",
    "    # 2文ずつの窓に分割\n",
    "    sentences = [s.strip() + \"。\" for s in re.split(r'(?<=。)', query_story) if s.strip()]\n",
    "    windows = [\"\".join(sentences[i:i+2]) for i in range(len(sentences)-1)] or [query_story]\n",
    "    \n",
    "    num_docs = len(base_df)\n",
    "    best_bm25_ranks = np.full(num_docs, num_docs)\n",
    "    best_vec_ranks = np.full(num_docs, num_docs)\n",
    "\n",
    "    for window in windows:\n",
    "        # BM25スコアリング\n",
    "        q_tokens = extract_nouns(window)\n",
    "        if q_tokens:\n",
    "            bm25_ranks = np.argsort(np.argsort(bm25.get_scores(q_tokens))[::-1]) + 1\n",
    "            best_bm25_ranks = np.minimum(best_bm25_ranks, bm25_ranks)\n",
    "        \n",
    "        # ベクトルスコアリング\n",
    "        q_emb = model.encode([\"query: \" + window], normalize_embeddings=True)\n",
    "        vec_ranks = np.argsort(np.argsort(cosine_similarity(q_emb, base_embeddings)[0])[::-1]) + 1\n",
    "        best_vec_ranks = np.minimum(best_vec_ranks, vec_ranks)\n",
    "\n",
    "    # RRF (Reciprocal Rank Fusion) で統合\n",
    "    rrf_scores = (1.0 / (k + best_bm25_ranks)) + (1.0 / (k + best_vec_ranks))\n",
    "    top_indices = np.argsort(rrf_scores)[::-1]\n",
    "    \n",
    "    return base_df.iloc[top_indices].assign(search_score=rrf_scores[top_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6aea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, top_n=10):\n",
    "    perfect_matches = 0 # 上位2件が正解ペア\n",
    "    both_in_top_n = 0   # 上位N件に2つとも含まれる\n",
    "    total_cases = len(df)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        preds = hybrid_window_search(row['story'])\n",
    "        top_ids = preds['id'].values\n",
    "        \n",
    "        true_ids = {row['id_a'], row['id_b']}\n",
    "        if set(top_ids[:2]) == true_ids:\n",
    "            perfect_matches += 1\n",
    "        \n",
    "        if len(set(top_ids[:top_n]).intersection(true_ids)) == 2:\n",
    "            both_in_top_n += 1\n",
    "\n",
    "    print(f\"Perfect Match Accuracy (Top 2): {perfect_matches/total_cases:.2%}\")\n",
    "    print(f\"Both in Top-{top_n}: {both_in_top_n/total_cases:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4bdfdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predictions for test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [01:35<00:00,  3.54it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "print(\"Starting predictions for test data...\")\n",
    "\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    search_results = hybrid_window_search(row['story'])\n",
    "    # スコア上位2件を選択し、IDを昇順に並べ替え\n",
    "    top_2_ids = sorted(search_results['id'].head(2).values)\n",
    "    results.append([row['id'], top_2_ids[0], top_2_ids[1]])\n",
    "\n",
    "# 提出用DataFrame作成\n",
    "submit_df = pd.DataFrame(results)\n",
    "# submit_df.to_csv('submission.csv', index=False, header=False)\n",
    "# print(\"Submission file created: submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57183f67",
   "metadata": {},
   "source": [
    "### モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e86d12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 20\n",
      "Evaluating...\n",
      "\n",
      "==============================\n",
      "【最終評価結果】\n",
      "完全一致数: 6 / 20\n",
      "正解率 (Accuracy): 30.00%\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# --- 最終評価: 練習用データでの正解率算出 ---\n",
    "\n",
    "def calculate_final_accuracy(df):\n",
    "    perfect_matches = 0\n",
    "    total_cases = len(df)\n",
    "    \n",
    "    print(f\"Total cases: {total_cases}\")\n",
    "    print(\"Evaluating...\")\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # 1. 検索実行\n",
    "        search_results = hybrid_window_search(row['story'])\n",
    "        \n",
    "        # 2. 上位2件のIDを取得（順不同で比較するため set を使用）\n",
    "        predicted_ids = set(search_results['id'].head(2).values)\n",
    "        true_ids = {row['id_a'], row['id_b']}\n",
    "        \n",
    "        # 3. 完全一致判定\n",
    "        if predicted_ids == true_ids:\n",
    "            perfect_matches += 1\n",
    "\n",
    "    # 正解率の算出\n",
    "    accuracy = perfect_matches / total_cases\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"【最終評価結果】\")\n",
    "    print(f\"完全一致数: {perfect_matches} / {total_cases}\")\n",
    "    print(f\"正解率 (Accuracy): {accuracy:.2%}\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "# 実行\n",
    "calculate_final_accuracy(practice_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199e80a",
   "metadata": {},
   "source": [
    "### 追加分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0879bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 片方だけ正解パターンの抽出 ---\n",
    "\n",
    "def analyze_error_patterns(df):\n",
    "    error_data = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        preds = hybrid_window_search(row['story'])\n",
    "        top_2_ids = set(preds['id'].head(2).values)\n",
    "        true_ids = {row['id_a'], row['id_b']}\n",
    "        \n",
    "        matches = top_2_ids.intersection(true_ids)\n",
    "        num_matches = len(matches)\n",
    "        \n",
    "        # Top 10 に入っているかも確認\n",
    "        top_10_ids = set(preds['id'].head(10).values)\n",
    "        in_top_10 = len(top_10_ids.intersection(true_ids))\n",
    "        \n",
    "        error_data.append({\n",
    "            'practice_idx': i,\n",
    "            'match_type': 'Perfect' if num_matches == 2 else ('Partial' if num_matches == 1 else 'Zero'),\n",
    "            'found_ids': list(matches),\n",
    "            'missed_ids': list(true_ids - matches),\n",
    "            'top_10_recall': in_top_10\n",
    "        })\n",
    "    \n",
    "    analysis_results_df = pd.DataFrame(error_data)\n",
    "    return analysis_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18437ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- マッチングタイプの分布 ---\n",
      "match_type\n",
      "Partial    10\n",
      "Perfect     6\n",
      "Zero        4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 実行と集計\n",
    "error_analysis_df = analyze_error_patterns(practice_df)\n",
    "print(\"--- マッチングタイプの分布 ---\")\n",
    "print(error_analysis_df['match_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5e03451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# マッチタイプを変数に格納\n",
    "partial_cases = error_analysis_df[error_analysis_df['match_type'] == 'Partial']\n",
    "Perfect_cases = error_analysis_df[error_analysis_df['match_type'] == 'Perfect']\n",
    "Zero_cases = error_analysis_df[error_analysis_df['match_type'] == 'Zero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d3312cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['practice_idx', 'match_type', 'found_ids', 'missed_ids',\n",
       "       'top_10_recall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_cases.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6acd3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = practice_df.copy()\n",
    "df_analysis['match_type'] = error_analysis_df['match_type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4894b59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- マッチタイプ別の平均文字数 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Partial</th>\n",
       "      <td>358.000000</td>\n",
       "      <td>35.724253</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perfect</th>\n",
       "      <td>341.333333</td>\n",
       "      <td>25.437505</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zero</th>\n",
       "      <td>330.000000</td>\n",
       "      <td>28.401878</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean        std  count\n",
       "match_type                              \n",
       "Partial     358.000000  35.724253     10\n",
       "Perfect     341.333333  25.437505      6\n",
       "Zero        330.000000  28.401878      4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文章量（文字数）の比較\n",
    "df_analysis['story_len'] = df_analysis['story'].str.len()\n",
    "print(\"--- マッチタイプ別の平均文字数 ---\")\n",
    "df_analysis.groupby('match_type')['story_len'].agg(['mean', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e44a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. キーワード残存率の算出（理論：残っている単語が多いほどPerfectになりやすいか？）\n",
    "def get_retention_rate(row):\n",
    "    text = row['story']\n",
    "    # id_a, id_b それぞれの元ネタの単語集合を取得\n",
    "    words_a = set(base_df[base_df['id'] == row['id_a']]['keywords'].iloc[0])\n",
    "    words_b = set(base_df[base_df['id'] == row['id_b']]['keywords'].iloc[0])\n",
    "    \n",
    "    # 実際にあらすじに含まれている数\n",
    "    match_a = sum(1 for w in words_a if w in text) / len(words_a) if words_a else 0\n",
    "    match_b = sum(1 for w in words_b if w in text) / len(words_b) if words_b else 0\n",
    "    return (match_a + match_b) / 2\n",
    "\n",
    "# base_dfにkeywords列がない場合は事前に作成（以前のコードで作成済みと想定）\n",
    "if 'keywords' not in base_df.columns:\n",
    "    base_df['keywords'] = base_df['story'].apply(extract_nouns)\n",
    "\n",
    "df_analysis['avg_retention'] = df_analysis.apply(get_retention_rate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12212726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- マッチタイプ別のキーワード残存率(%) ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "match_type\n",
       "Partial    12.255139\n",
       "Perfect    11.359562\n",
       "Zero        9.447753\n",
       "Name: avg_retention, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- マッチタイプ別のキーワード残存率(%) ---\")\n",
    "df_analysis.groupby('match_type')['avg_retention'].mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad39dca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 見逃された回数が多いベース作品 ID ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>マトリックス</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>インターステラー</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>フルメタル・ジャケット</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>マッドマックス 怒りのデス・ロード</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>七人の侍</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id              title\n",
       "1    2             マトリックス\n",
       "4    5           インターステラー\n",
       "22  23        フルメタル・ジャケット\n",
       "23  24  マッドマックス 怒りのデス・ロード\n",
       "34  35               七人の侍"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missed_ids = []\n",
    "for ids in error_analysis_df['missed_ids']:\n",
    "    missed_ids.extend(ids)\n",
    "\n",
    "if missed_ids:\n",
    "    print(\"\\n--- 見逃された回数が多いベース作品 ID ---\")\n",
    "    missed_series = pd.Series(missed_ids).value_counts()\n",
    "    display(base_df[base_df['id'].isin(missed_series.index[:5])][['id', 'title']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8c038",
   "metadata": {},
   "source": [
    "### LLMの導入で、リランクキングを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03784db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.6-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.29.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.189.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.48.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (2.11.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "  Downloading google_auth-2.49.0.dev0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.27.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting cryptography>=38.0.3 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading cryptography-46.0.4-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.31.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.3.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google-generativeai) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=38.0.3->google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading cffi-2.0.0-cp313-cp313-win_amd64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.78.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.1 in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Requirement already satisfied: pycparser in c:\\users\\管理\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=2.0.0->cryptography>=38.0.3->google-auth>=2.15.0->google-generativeai) (2.22)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading google_generativeai-0.8.6-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.3/1.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.29.0-py3-none-any.whl (173 kB)\n",
      "Downloading google_auth-2.49.0.dev0-py3-none-any.whl (236 kB)\n",
      "Downloading google_api_python_client-2.189.0-py3-none-any.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.8/14.5 MB 9.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.9/14.5 MB 9.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.0/14.5 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.1/14.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.2/14.5 MB 10.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.1/14.5 MB 9.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.5 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading cryptography-46.0.4-cp311-abi3-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.8/3.5 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.4/3.5 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.3.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading httplib2-0.31.2-py3-none-any.whl (91 kB)\n",
      "Downloading proto_plus-1.27.1-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading cffi-2.0.0-cp313-cp313-win_amd64.whl (183 kB)\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: uritemplate, pyasn1, proto-plus, httplib2, googleapis-common-protos, cffi, pyasn1-modules, grpcio-status, cryptography, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.17.1\n",
      "    Uninstalling cffi-1.17.1:\n",
      "      Successfully uninstalled cffi-1.17.1\n",
      "Successfully installed cffi-2.0.0 cryptography-46.0.4 google-ai-generativelanguage-0.6.15 google-api-core-2.29.0 google-api-python-client-2.189.0 google-auth-2.49.0.dev0 google-auth-httplib2-0.3.0 google-generativeai-0.8.6 googleapis-common-protos-1.72.0 grpcio-status-1.71.2 httplib2-0.31.2 proto-plus-1.27.1 pyasn1-0.6.2 pyasn1-modules-0.4.2 uritemplate-4.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18ae9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import time\n",
    "from google.api_core import exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30a6bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyDj7R-6BvTq_AYvR3fdibXtqc7hbIZLz_E\")\n",
    "model_gemini = genai.GenerativeModel('models/gemini-1.5-flash') # 高速かつ無料枠に適したモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f976050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用可能なモデルの一覧を表示\n",
    "#print(\"--- 利用可能なモデル一覧 ---\")\n",
    "#for m in genai.list_models():\n",
    "#    if 'generateContent' in m.supported_generation_methods:\n",
    "#        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b56e11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_reranker_minimal(query_story, candidates_df):\n",
    "    \"\"\"\n",
    "    極限までトークンを節約したリランカー\n",
    "    \"\"\"\n",
    "    # 候補リストをさらに短縮（タイトルのみ、あらすじは50文字）\n",
    "    candidate_list = \"\"\n",
    "    for i, row in candidates_df.iterrows():\n",
    "        candidate_list += f\"ID:{row['id']}, タイトル:{row['title']}, 概要:{row['story'][:50]}...\\n\"\n",
    "\n",
    "    # プロンプトを極限まで短くする（英語を混ぜるとトークンが減る場合があります）\n",
    "    prompt = f\"\"\"\n",
    "Combine 2 movies from the list to make this story. Return ONLY 2 IDs.\n",
    "Story: {query_story[:200]}\n",
    "List:\n",
    "{candidate_list}\n",
    "Answer: (ID1, ID2)\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model_gemini.generate_content(prompt)\n",
    "        pred_ids = [int(s) for s in re.findall(r'\\d+', response.text)]\n",
    "        return pred_ids[:2] if len(pred_ids) >= 2 else candidates_df['id'].head(2).tolist()\n",
    "    except Exception as e:\n",
    "        # 429エラー等が出た場合は即座にフォールバックして待機時間を無駄にしない\n",
    "        return candidates_df['id'].head(2).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb50075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ultra_stable_eval(df, top_n=10):\n",
    "    perfect_matches = 0\n",
    "    total_cases = len(df)\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Starting Ultra-Stable Evaluation (1 request per minute)...\")\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=total_cases):\n",
    "        # 候補抽出\n",
    "        search_candidates = hybrid_window_search(row['story']).head(top_n)\n",
    "        \n",
    "        # リランカー実行\n",
    "        pred_ids = gemini_reranker_minimal(row['story'], search_candidates)\n",
    "        \n",
    "        # 判定\n",
    "        predicted_set = set(pred_ids)\n",
    "        true_set = {row['id_a'], row['id_b']}\n",
    "        is_perfect = (predicted_set == true_set)\n",
    "        if is_perfect:\n",
    "            perfect_matches += 1\n",
    "            \n",
    "        results.append({'idx': i, 'is_perfect': is_perfect})\n",
    "        \n",
    "        # 1件ごとに60秒待機（これが無料枠回避の鍵です）\n",
    "        if i < total_cases - 1: # 最後の1件以外\n",
    "            time.sleep(60) \n",
    "\n",
    "    accuracy = perfect_matches / total_cases\n",
    "    print(f\"\\n最終正解率: {accuracy:.2%} ({perfect_matches}/{total_cases})\")\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32c68411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ultra-Stable Evaluation (1 request per minute)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [19:04<00:00, 57.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "最終正解率: 30.00% (6/20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>is_perfect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx  is_perfect\n",
       "0     0       False\n",
       "1     1       False\n",
       "2     2        True\n",
       "3     3       False\n",
       "4     4       False\n",
       "5     5        True\n",
       "6     6        True\n",
       "7     7       False\n",
       "8     8       False\n",
       "9     9       False\n",
       "10   10       False\n",
       "11   11       False\n",
       "12   12        True\n",
       "13   13       False\n",
       "14   14        True\n",
       "15   15       False\n",
       "16   16       False\n",
       "17   17       False\n",
       "18   18       False\n",
       "19   19        True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results_df = run_ultra_stable_eval(practice_df)\n",
    "eval_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babfc2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
